{
  "accept-solution": "Accept Solution",
  "add-fim-provider": "Add FIM provider",
  "add-provider": "Add Provider",
  "api-key-placeholder": "API key or blank to use environment variable.",
  "api-key": "API Key",
  "api-path-placeholder": "Enter a hostname e.g 'localhost'",
  "api-path": "API Path",
  "applicable-ollama": "Applicable for some providers like Ollama",
  "auto-connect-as-provider": "Auto connect as provider",
  "automatic": "Automatic",
  "back": "Back",
  "cancel-edit": "Cancel edit",
  "cancel": "Cancel",
  "chat": "Chat",
  "chat-provider": "Chat provider",
  "clear-conversations": "Clear conversations",
  "connect": "Connect",
  "connected": "Connected!",
  "connecting": "Connecting...",
  "connection-failed": "Connection failed! Please check your connection and try again.",
  "consumer-connection": "Consumer Connection",
  "conversation-history": "Conversation History",
  "copy-code": "Copy Code",
  "copy-provider": "Copy Provider",
  "createFile": "Create file",
  "custom-provider": "Custom Provider",
  "default-settings": "Default settings",
  "delete-message": "Delete message",
  "delete-provider": "Delete Provider",
  "disconnect": "Disconnect",
  "edit-default-templates-description": "Edit the default templates used in the twinny extension.",
  "edit-default-templates": "Edit default templates",
  "edit-message": "Edit message",
  "edit-provider": "Edit Provider",
  "embed-documents": "Embed documents",
  "embedding-provider": "Embedding provider",
  "error": "Error",
  "fim-provider": "FIM Provider",
  "fim-providers": "FIM Providers",
  "fim-template": "FIM Template",
  "fim": "Fill-in-middle",
  "hostname-placeholder": "Enter a hostname e.g 'localhost'",
  "hostname": "Hostname",
  "label-placeholder": "Enter a label for your provider.",
  "label": "Label",
  "loading-available-models": "Loading available models...",
  "select-llm-provider": "Select LLM Provider",
  "max-chunk-size": "Max chunk size",
  "min-chunk-size": "Min chunk size",
  "model-name-placeholder": "Enter a model name e.g 'llama3'",
  "model-name": "Model Name",
  "new-conversation": "New Conversation",
  "new-document": "New Document",
  "no-connections-found": "No connections found. Please add a new connection to get started.",
  "no-result": "No result",
  "nothing-to-see-here": "Nothing to see here.",
  "number-code-filepaths": "The number of file paths to be used as context.",
  "number-code-snippets": "The number of code snippets to be used as context.",
  "open-diff": "Open Diff",
  "open-template-editor": "Open template editor",
  "openFile": "Open file",
  "overlap-size": "Overlap size",
  "owner-repo-name": "This tab will help you review pull requests in your repository, enter the owner and repository name below to get started. For now only GitHub is supported, set your GitHub token in the settings tab to get started.",
  "path": "Path",
  "pending": "Pending",
  "placeholder": "How can twinny help you today?",
  "port-placeholder": "Enter a port number e.g '11434'",
  "port": "Port",
  "protocol": "Protocol",
  "provider-connection": "Provider Connection",
  "provider-name": "Provider Name",
  "provider-placeholder": "Enter a provider name",
  "provider-type": "Provider Type",
  "provider": "Provider",
  "providers": "Providers",
  "pull-requests": "Pull Requests",
  "regenerate-message": "Regenerate message",
  "relevant-code-snippets": "Relevant code snippets",
  "relevant-file-paths": "Relevant file paths",
  "remove": "Remove",
  "repository-level": "Repository level",
  "rerank-probability-threshold": "Rerank probability threshold",
  "rerank-threshold-description": "The lower the threshold, the more likely a result is to be included.",
  "rerank-threshold": "Rerank threshold",
  "reset-providers": "Reset Providers",
  "reset-to-default": "Reset to default",
  "review-pull-requests": "Review pull requests",
  "run-all": "Run All",
  "run": "Run",
  "runCommand": "Run command",
  "running": "Running",
  "save-edit": "Save edit",
  "save": "Save",
  "select-provider": "Select Provider",
  "scroll-down": "Scroll down to the bottom",
  "select-model": "Select model",
  "share-gpu-resources": "You can also share your GPU resources by connecting to Symmetry as a provider using your active twinny provider configuration. All connections are peer to peer, encrypted end-to-end and secure.",
  "status": "Status",
  "stop-generation": "Stop generation",
  "success": "Success",
  "symmetry-description": "Symmetry is a peer-to-peer AI inference network that allows secure, direct connections between users. When you connect as a consumer, Symmetry matches you with a provider based on your model selection.",
  "symmetry-inference-network": "Symmetry Inference Network",
  "template-settings-description": "Select the templates you want to use in the chat interface.",
  "template-settings": "Template settings",
  "thinking": "Thinking...",
  "toggle-auto-scroll": "Toggle auto scroll on/off",
  "toggle-embedding-options": "Toggle embedding options on/off",
  "toggle-provider-selection": "Toggle provider selection",
  "tools": "Tools",
  "toggle-defaults": "View default configuration",
  "type": "Type"
}
